{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need this? \n",
    "\n",
    "\n",
    "We are trying to solve several problems by proposing a new file format. Specifically: \n",
    "\n",
    "* Saving each conformation as individual file is producing too many files\n",
    "* Using pickle-based approaches (joblib) makes format python-specific and not backwards compatible; text is clumsy\n",
    "* Would be nice to save metadata, such as starting conformation, forces, or initial parameters. \n",
    "\n",
    "\n",
    "Are there alternatives?  I considered MDTraj compatible binary formats. They are PDB centered, and are usually one-file-per-trajectory. It looked hacky. \n",
    "\n",
    "### one file vs  many files  vs  several files \n",
    "\n",
    "Saving each conformation as an individual file is undesirable because it will produce too many files: filesystem check or backup on 30,000,000 files takes hours/days. \n",
    "\n",
    "Saving all trajectory as a single files is undesirable because 1. backup software will back up a new copy of the file every day as it grows; and 2. if the last write fails, the file will end up in the corrupted state and would need to be recovered. \n",
    "\n",
    "Solution is: save groups of conformations as individual files. E.g. save conformations 1-50 as one file, conformations 51-100 as a second file etc. \n",
    "\n",
    "This way, we are not risking to lose anything if the power goes out at the end. This way, we are not screwing with backup solutions, And we also have partial trajectories that can be analyzed. \n",
    "\n",
    "\n",
    "### Storage format - what did I choose? \n",
    "\n",
    "I chose the HDF5-based storage that roughly mimics the MDTraj HDF5 format. It does not have MDTraj topology because it seemed a little too complicated, and not compatible with nglview anyways. Maybe one day we will write something that fully converts it to MDTraj if necessary. \n",
    "\n",
    "\n",
    "### Overall design of the format\n",
    "\n",
    "\n",
    "I decided to separate two entitys: a simulation object and a reporter. When a simulation object is initialized, a reporter (actually, a list of reporters in case you want to use several) is passed to the simulation object. Simulation object would attempt to save several things: __init__ arguments, starting conformation, energy minimization results (TODO), serialized forces, and blocks of conformations together with time, Ek, Ep. \n",
    "\n",
    "Each time a simulation object wants to save something, it calls reporter.report(...) for each of the reporters. It passes a string indicating what is being reported, and a dictionary to save. Reporter will have to interpret this and save the data. Reporter is also keeping appropriate counts. NOTE: generic Python objects are not supported. It has to be HDF5-compatible, meaning an array of numbers/strings, or a number/string. \n",
    "\n",
    "The HDF5 reporter used here saves everything into an HDF5 file. For anything except for a conformation, it would immmediately save the data into a single HDF5 file: numpy array compatible structures would be saved as datasets, and regular types (strings, numbers) would be saved as attributes. For conformations, it would wait until a certain number of conformations is received. It will then save them all at once into an HDF5 file under groups /1, /2, /3... /50 for blocks 1,2,3...50 respectively, and save them to \"blocks_1-50.h5\" file\n",
    "\n",
    "\n",
    "### Multi-stage simulations or loop extrusion\n",
    "\n",
    "We frequently have simulations in which a simulation object changes. One example would be changing forces or parameters throughout the simulation. Another example would be loop extrusion simulations. \n",
    "\n",
    "In this design, a reporter object can be reused and passed to a new simulation. This would keep counter of conformations, and also save applied forces etc. again. The reporter would create a file \"applied_forces_0.h5\" the first time it receives forces, and \"applied_forces_1.h5\" the second time it receives forces from a simulation. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polychrom\n",
    "import numpy as np \n",
    "import warnings\n",
    "import h5py \n",
    "import glob\n",
    "from polychrom.simulation import Simulation\n",
    "import polychrom.starting_conformations\n",
    "import polychrom.forces, polychrom.forcekits\n",
    "import simtk.openmm \n",
    "import os \n",
    "import shutil\n",
    "import polychrom.polymerutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading reporter and utils from a hdf5_format module \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polychrom.hdf5_format import hdf5Reporter, list_filenames, load_block, load_hdf5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a simulation and passing a reporter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:adding force HarmonicBonds 0\n",
      "INFO:root:adding force Angle 1\n",
      "INFO:root:adding force PolynomialRepulsive 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude neighbouring chain particles from PolynomialRepulsive\n",
      "Number of exceptions: 9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Particles loaded. Potential energy is 0.050625\n",
      "INFO:root:block    1 pos[1]=[14.2 14.0 14.0] dr=0.21 t=0.9ps kin=8.29 pot=4.02 Rg=11.082 dt=24.0fs dx=15.42pm \n",
      "INFO:root:block    2 pos[1]=[14.2 14.0 14.0] dr=0.17 t=1.2ps kin=3.89 pot=8.97 Rg=11.083 dt=20.5fs dx=9.02pm \n",
      "INFO:root:block    3 pos[1]=[14.3 14.0 14.1] dr=0.09 t=1.4ps kin=7.88 pot=5.02 Rg=11.084 dt=24.6fs dx=15.40pm \n",
      "INFO:root:block    4 pos[1]=[14.4 13.9 14.1] dr=0.14 t=1.6ps kin=6.29 pot=6.63 Rg=11.089 dt=22.0fs dx=12.34pm \n",
      "INFO:root:block    5 pos[1]=[14.5 13.9 14.1] dr=0.11 t=1.8ps kin=6.93 pot=5.97 Rg=11.094 dt=21.8fs dx=12.80pm \n",
      "INFO:root:block    6 pos[1]=[14.5 13.9 14.1] dr=0.12 t=2.0ps kin=6.82 pot=6.06 Rg=11.098 dt=21.8fs dx=12.70pm \n",
      "INFO:root:block    7 pos[1]=[14.5 13.8 14.1] dr=0.12 t=2.3ps kin=6.95 pot=5.89 Rg=11.103 dt=21.8fs dx=12.83pm \n",
      "INFO:root:block    8 pos[1]=[14.5 13.8 14.1] dr=0.12 t=2.5ps kin=7.28 pot=5.55 Rg=11.108 dt=21.8fs dx=13.12pm \n",
      "INFO:root:block    9 pos[1]=[14.6 13.8 14.0] dr=0.12 t=2.7ps kin=6.74 pot=6.06 Rg=11.115 dt=21.8fs dx=12.63pm \n",
      "INFO:root:block   10 pos[1]=[14.6 13.8 14.0] dr=0.12 t=2.9ps kin=7.24 pot=5.53 Rg=11.122 dt=21.8fs dx=13.09pm \n",
      "INFO:root:block   11 pos[1]=[14.6 13.9 14.0] dr=0.12 t=3.1ps kin=6.87 pot=5.88 Rg=11.129 dt=21.8fs dx=12.75pm \n",
      "INFO:root:block   12 pos[1]=[14.6 13.9 14.0] dr=0.12 t=3.3ps kin=7.13 pot=5.59 Rg=11.137 dt=21.8fs dx=12.99pm \n",
      "INFO:root:block   13 pos[1]=[14.6 13.9 13.9] dr=0.12 t=3.6ps kin=6.95 pot=5.75 Rg=11.146 dt=21.8fs dx=12.82pm \n",
      "INFO:root:block   14 pos[1]=[14.6 13.9 13.9] dr=0.12 t=3.8ps kin=7.09 pot=5.59 Rg=11.156 dt=21.8fs dx=12.95pm \n",
      "INFO:root:block   15 pos[1]=[14.6 13.9 13.8] dr=0.12 t=4.0ps kin=7.07 pot=5.58 Rg=11.166 dt=21.8fs dx=12.93pm \n",
      "INFO:root:block   16 pos[1]=[14.5 13.8 13.7] dr=0.12 t=4.2ps kin=7.01 pot=5.62 Rg=11.176 dt=21.8fs dx=12.88pm \n",
      "INFO:root:block   17 pos[1]=[14.5 13.8 13.7] dr=0.12 t=4.4ps kin=7.07 pot=5.53 Rg=11.188 dt=21.8fs dx=12.94pm \n",
      "INFO:root:block   18 pos[1]=[14.4 13.8 13.6] dr=0.12 t=4.6ps kin=7.04 pot=5.54 Rg=11.200 dt=21.8fs dx=12.91pm \n",
      "INFO:root:block   19 pos[1]=[14.3 13.8 13.5] dr=0.12 t=4.9ps kin=7.20 pot=5.35 Rg=11.212 dt=21.8fs dx=13.05pm \n"
     ]
    }
   ],
   "source": [
    "%rm  test/*\n",
    "data = polychrom.starting_conformations.grow_cubic(10000,30)\n",
    "\n",
    "\"\"\"\n",
    "Here we created a hdf5Reporter attached to a foler test, and we are saving 5 blocks per file \n",
    "(you should probalby use 50 here or 100. 5 is just for a showcase)\n",
    "\"\"\"\n",
    "reporter = hdf5Reporter(folder=\"test\", max_data_length=5)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Passing a reporter to the simulation object - many reporters are possible, and more will be added in a future\n",
    "\"\"\"\n",
    "sim = Simulation(N=10000, error_tol=0.001, collision_rate=0.01, integrator =\"variableLangevin\", platform=\"CPU\", \n",
    "                reporters=[reporter])\n",
    "sim.setData(data)\n",
    "sim.addForce(polychrom.forcekits.polymerChains(sim))\n",
    "sim._applyForces()\n",
    "sim.addForce(polychrom.forces.sphericalConfinement(sim, density=0.1))\n",
    "\n",
    "\n",
    "for i in range(19):        \n",
    "    \"\"\"\n",
    "    Here we pass two extra records: a string and an array-like object.\n",
    "    First becomes an attr, and second becomes an HDF5 dataset\n",
    "    \"\"\"\n",
    "    sim.doBlock(10, saveExtras={\"eggs\": \"I don't eat green eggs and ham!!!\", \"spam\":[1,2,3]})\n",
    "\n",
    "\"\"\"\n",
    "Here we are not forgetting to dump the last set of blocks that the reporter has. \n",
    "We have to do it at the end of every simulation. \n",
    "\n",
    "I tried adding it to the destructor to make it automatic,\n",
    "but some weird interactions with garbage collection made it not very useable. \n",
    "\"\"\"\n",
    "reporter.dump_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a list of files created in the trajectory forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6116\r\n",
      "drwxrwxr-x 2 magus magus    4096 Aug 24 17:50 .\r\n",
      "drwxrwxr-x 4 magus magus    4096 Aug 24 17:49 ..\r\n",
      "-rw-rw-r-- 1 magus magus 1615688 Aug 24 17:50 applied_forces_0.hdf5\r\n",
      "-rw-rw-r-- 1 magus magus 1167792 Aug 24 17:50 blocks_0-4.h5\r\n",
      "-rw-rw-r-- 1 magus magus 1170145 Aug 24 17:50 blocks_10-14.h5\r\n",
      "-rw-rw-r-- 1 magus magus  937745 Aug 24 17:50 blocks_15-18.h5\r\n",
      "-rw-rw-r-- 1 magus magus 1169806 Aug 24 17:50 blocks_5-9.h5\r\n",
      "-rw-rw-r-- 1 magus magus    6144 Aug 24 17:50 initArgs_0.hdf5\r\n",
      "-rw-rw-r-- 1 magus magus  174714 Aug 24 17:50 starting_conformation_0.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/blocks_0-4.h5::0',\n",
       " 'test/blocks_0-4.h5::1',\n",
       " 'test/blocks_0-4.h5::2',\n",
       " 'test/blocks_0-4.h5::3',\n",
       " 'test/blocks_0-4.h5::4',\n",
       " 'test/blocks_5-9.h5::5',\n",
       " 'test/blocks_5-9.h5::6',\n",
       " 'test/blocks_5-9.h5::7',\n",
       " 'test/blocks_5-9.h5::8',\n",
       " 'test/blocks_5-9.h5::9',\n",
       " 'test/blocks_10-14.h5::10',\n",
       " 'test/blocks_10-14.h5::11',\n",
       " 'test/blocks_10-14.h5::12',\n",
       " 'test/blocks_10-14.h5::13',\n",
       " 'test/blocks_10-14.h5::14',\n",
       " 'test/blocks_15-18.h5::15',\n",
       " 'test/blocks_15-18.h5::16',\n",
       " 'test/blocks_15-18.h5::17',\n",
       " 'test/blocks_15-18.h5::18']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list_filenames(\"test\")\n",
    "files   #  these are the paths for individual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': array([[14.20045833, 13.99957801, 14.01093603],\n",
       "        [13.16833939, 13.95647912, 14.02223415],\n",
       "        [12.87320312, 13.78728574, 13.0657144 ],\n",
       "        ...,\n",
       "        [14.96041728, 14.89754   , 12.91137594],\n",
       "        [15.08821625, 14.97620249, 13.82370166],\n",
       "        [13.95099467, 14.94128795, 14.0282529 ]]),\n",
       " 'spam': array([1, 2, 3]),\n",
       " 'block': 1,\n",
       " 'eggs': \"I don't eat green eggs and ham!!!\",\n",
       " 'kineticEnergy': 8.293918776505691,\n",
       " 'potentialEnergy': 4.016401203546876,\n",
       " 'time': 0.8851873628976735}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading the entire file, with position and other information\n",
    "for that, use polychrom.hdf5_format.load_block\n",
    "\n",
    "Note how our custom-added eggs and spam appear below. \n",
    "\n",
    "\"\"\"\n",
    "load_block(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.20045833, 13.99957801, 14.01093603],\n",
       "       [13.16833939, 13.95647912, 14.02223415],\n",
       "       [12.87320312, 13.78728574, 13.0657144 ],\n",
       "       ...,\n",
       "       [14.96041728, 14.89754   , 12.91137594],\n",
       "       [15.08821625, 14.97620249, 13.82370166],\n",
       "       [13.95099467, 14.94128795, 14.0282529 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "It is backwards compatible with polymerutils.load as well, and it gives you just the XYZ\n",
    "\"\"\"\n",
    "polychrom.polymerutils.load(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU': '0',\n",
       " 'N': 10000,\n",
       " 'PBC': False,\n",
       " 'collision_rate': 0.01,\n",
       " 'error_tol': 0.001,\n",
       " 'integrator': 'variableLangevin',\n",
       " 'length_scale': 1.0,\n",
       " 'mass': 100,\n",
       " 'maxEk': 10,\n",
       " 'name': 'sim',\n",
       " 'platform': 'CPU',\n",
       " 'precision': 'mixed',\n",
       " 'temperature': 300,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finally, loading the saved file with initial conformations. \n",
    "\"\"\"\n",
    "load_hdf5_file(\"test/initArgs_0.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple things are saved as attrs\n",
      "('GPU', '0')\n",
      "('N', 10000)\n",
      "('PBC', False)\n",
      "('collision_rate', 0.01)\n",
      "('error_tol', 0.001)\n",
      "('integrator', 'variableLangevin')\n",
      "('length_scale', 1.0)\n",
      "('mass', 100)\n",
      "('maxEk', 10)\n",
      "('name', 'sim')\n",
      "('platform', 'CPU')\n",
      "('precision', 'mixed')\n",
      "('temperature', 300)\n",
      "('verbose', False)\n",
      "\n",
      " groups are: \n",
      "[('15', <HDF5 group \"/15\" (2 members)>), ('16', <HDF5 group \"/16\" (2 members)>), ('17', <HDF5 group \"/17\" (2 members)>), ('18', <HDF5 group \"/18\" (2 members)>)]\n",
      "\n",
      " looking at block 15 datasets\n",
      "[('pos', <HDF5 dataset \"pos\": shape (10000, 3), type \"<f8\">), ('spam', <HDF5 dataset \"spam\": shape (3,), type \"<i8\">)]\n",
      "\n",
      " looking at block 15 attrs\n",
      "[('block', 16), ('eggs', \"I don't eat green eggs and ham!!!\"), ('kineticEnergy', 7.011314701711484), ('potentialEnergy', 5.615686917628971), ('time', 4.21041506346761)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "And how it actually looks in HDF5\n",
    "\"\"\"\n",
    "import h5py \n",
    "\n",
    "print(\"simple things are saved as attrs\")\n",
    "\n",
    "for i in h5py.File(\"test/initArgs_0.hdf5\").attrs.items():\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "myfile = h5py.File(\"test/blocks_15-18.h5\",'r') \n",
    "\n",
    "print(\"\\n groups are: \")\n",
    "print(list(myfile.items()))\n",
    "\n",
    "\n",
    "print(\"\\n looking at block 15 datasets\")\n",
    "print(list(myfile[\"15\"].items()))\n",
    "\n",
    "\n",
    "print(\"\\n looking at block 15 attrs\")\n",
    "print(list(myfile[\"15\"].attrs.items()))\n",
    "\n",
    "\n",
    "print(\"Note: block 16 is a block number inside of the simulation object, not the group number (her)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
