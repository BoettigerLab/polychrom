{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need this? \n",
    "\n",
    "\n",
    "We are trying to solve several problems by proposing a new file format. Specifically: \n",
    "\n",
    "* Saving each conformation as individual file is producing too many files\n",
    "* Using pickle-based approaches (joblib) makes format python-specific and not backwards compatible; text is clumsy\n",
    "* Would be nice to save metadata, such as starting conformation, forces, or initial parameters. \n",
    "\n",
    "\n",
    "Are there alternatives?  I considered MDTraj compatible binary formats. They are PDB centered, and are usually one-file-per-trajectory. It looked hacky. \n",
    "\n",
    "### one file vs  many files  vs  several files \n",
    "\n",
    "Saving each conformation as an individual file is undesirable because it will produce too many files: filesystem check or backup on 30,000,000 files takes hours/days. \n",
    "\n",
    "Saving all trajectory as a single files is undesirable because 1. backup software will back up a new copy of the file every day as it grows; and 2. if the last write fails, the file will end up in the corrupted state and would need to be recovered. \n",
    "\n",
    "Solution is: save groups of conformations as individual files. E.g. save conformations 1-50 as one file, conformations 51-100 as a second file etc. \n",
    "\n",
    "This way, we are not risking to lose anything if the power goes out at the end. This way, we are not screwing with backup solutions, And we also have partial trajectories that can be analyzed. \n",
    "\n",
    "\n",
    "### Storage format - what did I choose? \n",
    "\n",
    "I chose the HDF5-based storage that roughly mimics the MDTraj HDF5 format. It does not have MDTraj topology because it seemed a little too complicated, and not compatible with nglview anyways. Maybe one day we will write something that fully converts it to MDTraj if necessary. \n",
    "\n",
    "\n",
    "### Overall design of the format\n",
    "\n",
    "\n",
    "I decided to separate two entitys: a simulation object and a reporter. When a simulation object is initialized, a reporter (actually, a list of reporters in case you want to use several) is passed to the simulation object. Simulation object would attempt to save several things: __init__ arguments, starting conformation, energy minimization results (TODO), serialized forces, and blocks of conformations together with time, Ek, Ep. \n",
    "\n",
    "Each time a simulation object wants to save something, it calls reporter.report(...) for each of the reporters. It passes a string indicating what is being reported, and a dictionary to save. Reporter will have to interpret this and save the data. Reporter is also keeping appropriate counts. NOTE: generic Python objects are not supported. It has to be HDF5-compatible, meaning an array of numbers/strings, or a number/string. \n",
    "\n",
    "The HDF5 reporter used here saves everything into an HDF5 file. For anything except for a conformation, it would immmediately save the data into a single HDF5 file: numpy array compatible structures would be saved as datasets, and regular types (strings, numbers) would be saved as attributes. For conformations, it would wait until a certain number of conformations is received. It will then save them all at once into an HDF5 file under groups /1, /2, /3... /50 for blocks 1,2,3...50 respectively, and save them to `blocks_1-50.h5` file\n",
    "\n",
    "\n",
    "### Multi-stage simulations or loop extrusion\n",
    "\n",
    "We frequently have simulations in which a simulation object changes. One example would be changing forces or parameters throughout the simulation. Another example would be loop extrusion simulations. \n",
    "\n",
    "In this design, a reporter object can be reused and passed to a new simulation. This would keep counter of conformations, and also save applied forces etc. again. The reporter would create a file \"applied_forces_0.h5\" the first time it receives forces, and \"applied_forces_1.h5\" the second time it receives forces from a simulation. \n",
    "\n",
    "\n",
    "### URIs to identify individual conformations\n",
    "\n",
    "Because we're saving several conformations into one file, we designed an URI format to quickly fetch a conformation by a unique identifyer. \n",
    "\n",
    "URIs are like that: `/path/to/the/trajectory/blocks_1-50.h5::42` \n",
    "\n",
    "This URI will fetch block #42 from a file blocks_1-50.h5, which contains blocks 1 through 50 including 1 and 50\n",
    "\n",
    "polymerutils.load are compatible with URIs \n",
    "\n",
    "Also, to make it easy to load both old-style filenames and new-style URIs, there is a function polychrom.polymerutils.fetch_block\n",
    "\n",
    "fetch_block will autodetermine the type of a trajectory folder. \n",
    "\n",
    "So it will fetch both `/path/to/the/trajectory/block42.dat` and  `/path/to/the/trajectory/blocks_x-y.h5::42` automatically \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polychrom\n",
    "import numpy as np \n",
    "import warnings\n",
    "import h5py \n",
    "import glob\n",
    "from polychrom.simulation import Simulation\n",
    "import polychrom.starting_conformations\n",
    "import polychrom.forces, polychrom.forcekits\n",
    "import simtk.openmm \n",
    "import os \n",
    "import shutil\n",
    "import polychrom.polymerutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading reporter and utils from a hdf5_format module \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polychrom.hdf5_format import HDF5Reporter, list_URIs, load_URI, load_hdf5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a simulation and passing a reporter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:adding force HarmonicBonds 0\n",
      "INFO:root:adding force Angle 1\n",
      "INFO:root:adding force PolynomialRepulsive 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude neighbouring chain particles from PolynomialRepulsive\n",
      "Number of exceptions: 9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Particles loaded. Potential energy is 0.050502\n",
      "INFO:root:block    0 pos[1]=[13.8 13.9 13.9] dr=0.21 t=0.9ps kin=8.19 pot=3.99 Rg=11.059 dt=24.1fs dx=15.40pm \n",
      "INFO:root:block    1 pos[1]=[13.8 13.8 13.9] dr=0.17 t=1.2ps kin=3.83 pot=8.88 Rg=11.059 dt=20.6fs dx=8.99pm \n",
      "INFO:root:block    2 pos[1]=[13.8 13.8 13.9] dr=0.09 t=1.4ps kin=7.70 pot=5.06 Rg=11.060 dt=24.5fs dx=15.19pm \n",
      "INFO:root:block    3 pos[1]=[13.7 13.7 13.9] dr=0.14 t=1.6ps kin=6.31 pot=6.46 Rg=11.064 dt=22.3fs dx=12.50pm \n",
      "INFO:root:block    4 pos[1]=[13.7 13.7 13.9] dr=0.11 t=1.8ps kin=6.69 pot=6.06 Rg=11.069 dt=22.0fs dx=12.71pm \n",
      "INFO:root:block    5 pos[1]=[13.7 13.7 13.8] dr=0.12 t=2.0ps kin=6.88 pot=5.85 Rg=11.074 dt=22.0fs dx=12.89pm \n",
      "INFO:root:block    6 pos[1]=[13.7 13.6 13.8] dr=0.12 t=2.3ps kin=6.77 pot=5.93 Rg=11.078 dt=22.0fs dx=12.78pm \n",
      "INFO:root:block    7 pos[1]=[13.7 13.5 13.8] dr=0.12 t=2.5ps kin=7.27 pot=5.41 Rg=11.084 dt=22.0fs dx=13.24pm \n",
      "INFO:root:block    8 pos[1]=[13.7 13.5 13.8] dr=0.12 t=2.7ps kin=6.67 pot=5.99 Rg=11.090 dt=22.0fs dx=12.69pm \n",
      "INFO:root:block    9 pos[1]=[13.7 13.5 13.7] dr=0.12 t=2.9ps kin=7.12 pot=5.51 Rg=11.097 dt=22.0fs dx=13.11pm \n",
      "INFO:root:block   10 pos[1]=[13.7 13.5 13.7] dr=0.12 t=3.1ps kin=6.77 pot=5.84 Rg=11.105 dt=22.0fs dx=12.79pm \n",
      "INFO:root:block   11 pos[1]=[13.7 13.5 13.7] dr=0.12 t=3.4ps kin=7.04 pot=5.55 Rg=11.113 dt=22.0fs dx=13.03pm \n",
      "INFO:root:block   12 pos[1]=[13.8 13.5 13.7] dr=0.12 t=3.6ps kin=6.93 pot=5.63 Rg=11.122 dt=22.0fs dx=12.93pm \n",
      "INFO:root:block   13 pos[1]=[13.8 13.5 13.7] dr=0.12 t=3.8ps kin=6.94 pot=5.60 Rg=11.131 dt=22.0fs dx=12.94pm \n",
      "INFO:root:block   14 pos[1]=[13.8 13.6 13.7] dr=0.12 t=4.0ps kin=7.01 pot=5.50 Rg=11.141 dt=22.0fs dx=13.01pm \n",
      "INFO:root:block   15 pos[1]=[13.8 13.6 13.7] dr=0.12 t=4.2ps kin=6.89 pot=5.61 Rg=11.152 dt=22.0fs dx=12.89pm \n",
      "INFO:root:block   16 pos[1]=[13.8 13.6 13.7] dr=0.12 t=4.5ps kin=7.10 pot=5.36 Rg=11.163 dt=22.0fs dx=13.09pm \n",
      "INFO:root:block   17 pos[1]=[13.8 13.6 13.8] dr=0.12 t=4.7ps kin=6.90 pot=5.55 Rg=11.175 dt=22.0fs dx=12.90pm \n",
      "INFO:root:block   18 pos[1]=[13.9 13.6 13.8] dr=0.12 t=4.9ps kin=7.04 pot=5.38 Rg=11.188 dt=22.0fs dx=13.04pm \n"
     ]
    }
   ],
   "source": [
    "%rm  test/*\n",
    "data = polychrom.starting_conformations.grow_cubic(10000,30)\n",
    "\n",
    "\"\"\"\n",
    "Here we created a hdf5Reporter attached to a foler test, and we are saving 5 blocks per file \n",
    "(you should probalby use 50 here or 100. 5 is just for a showcase)\n",
    "\"\"\"\n",
    "reporter = HDF5Reporter(folder=\"test\", max_data_length=5)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Passing a reporter to the simulation object - many reporters are possible, and more will be added in a future\n",
    "\"\"\"\n",
    "sim = Simulation(N=10000, error_tol=0.001, collision_rate=0.01, integrator =\"variableLangevin\", platform=\"CPU\", \n",
    "                reporters=[reporter])\n",
    "sim.set_data(data)\n",
    "sim.add_force(polychrom.forcekits.polymerChains(sim))\n",
    "sim._apply_forces()\n",
    "sim.add_force(polychrom.forces.sphericalConfinement(sim, density=0.1))\n",
    "\n",
    "\n",
    "for i in range(19):        \n",
    "    \"\"\"\n",
    "    Here we pass two extra records: a string and an array-like object.\n",
    "    First becomes an attr, and second becomes an HDF5 dataset\n",
    "    \"\"\"\n",
    "    sim.do_block(10, save_extras={\"eggs\": \"I don't eat green eggs and ham!!!\", \"spam\":[1,2,3]})\n",
    "\n",
    "\"\"\"\n",
    "Here we are not forgetting to dump the last set of blocks that the reporter has. \n",
    "We have to do it at the end of every simulation. \n",
    "\n",
    "I tried adding it to the destructor to make it automatic,\n",
    "but some weird interactions with garbage collection made it not very useable. \n",
    "\"\"\"\n",
    "reporter.dump_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a list of files created in the trajectory folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6116\r\n",
      "drwxrwxr-x 2 magus magus    4096 Sep  2 18:19 .\r\n",
      "drwxrwxr-x 5 magus magus    4096 Sep  2 18:19 ..\r\n",
      "-rw-rw-r-- 1 magus magus 1615688 Sep  2 18:19 applied_forces_0.h5\r\n",
      "-rw-rw-r-- 1 magus magus 1167760 Sep  2 18:19 blocks_0-4.h5\r\n",
      "-rw-rw-r-- 1 magus magus 1169873 Sep  2 18:19 blocks_10-14.h5\r\n",
      "-rw-rw-r-- 1 magus magus  937585 Sep  2 18:19 blocks_15-18.h5\r\n",
      "-rw-rw-r-- 1 magus magus 1169785 Sep  2 18:19 blocks_5-9.h5\r\n",
      "-rw-rw-r-- 1 magus magus    6144 Sep  2 18:19 initArgs_0.h5\r\n",
      "-rw-rw-r-- 1 magus magus  174847 Sep  2 18:19 starting_conformation_0.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/blocks_0-4.h5::0',\n",
       " 'test/blocks_0-4.h5::1',\n",
       " 'test/blocks_0-4.h5::2',\n",
       " 'test/blocks_0-4.h5::3',\n",
       " 'test/blocks_0-4.h5::4',\n",
       " 'test/blocks_5-9.h5::5',\n",
       " 'test/blocks_5-9.h5::6',\n",
       " 'test/blocks_5-9.h5::7',\n",
       " 'test/blocks_5-9.h5::8',\n",
       " 'test/blocks_5-9.h5::9',\n",
       " 'test/blocks_10-14.h5::10',\n",
       " 'test/blocks_10-14.h5::11',\n",
       " 'test/blocks_10-14.h5::12',\n",
       " 'test/blocks_10-14.h5::13',\n",
       " 'test/blocks_10-14.h5::14',\n",
       " 'test/blocks_15-18.h5::15',\n",
       " 'test/blocks_15-18.h5::16',\n",
       " 'test/blocks_15-18.h5::17',\n",
       " 'test/blocks_15-18.h5::18']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list_URIs(\"test\")\n",
    "files   #  these are the URIs for individual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': array([[13.80736589, 13.86134737, 13.91210916],\n",
       "        [14.19402612, 12.96560652, 14.12108859],\n",
       "        [13.87467106, 13.15338213, 14.94710676],\n",
       "        ...,\n",
       "        [13.85326369, 12.93188278, 12.06708795],\n",
       "        [13.9344306 , 14.05768812, 12.03921379],\n",
       "        [14.01382148, 14.29979772, 13.06234489]]),\n",
       " 'spam': array([1, 2, 3]),\n",
       " 'block': 0,\n",
       " 'eggs': \"I don't eat green eggs and ham!!!\",\n",
       " 'kineticEnergy': 8.18619630961378,\n",
       " 'potentialEnergy': 3.9903573396415153,\n",
       " 'time': 0.8845543379323831}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading the entire blosk by URI, with position and other information\n",
    "for that, use polychrom.hdf5_format.load_URI\n",
    "\n",
    "Note how our custom-added eggs and spam appear below. \n",
    "\n",
    "\"\"\"\n",
    "load_URI(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.80736589, 13.86134737, 13.91210916],\n",
       "       [14.19402612, 12.96560652, 14.12108859],\n",
       "       [13.87467106, 13.15338213, 14.94710676],\n",
       "       ...,\n",
       "       [13.85326369, 12.93188278, 12.06708795],\n",
       "       [13.9344306 , 14.05768812, 12.03921379],\n",
       "       [14.01382148, 14.29979772, 13.06234489]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "It is backwards compatible with polymerutils.load as well, and it gives you just the XYZ\n",
    "\"\"\"\n",
    "polychrom.polymerutils.load(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.76909954, 13.75941642, 13.88492131],\n",
       "       [14.32039342, 12.95625228, 14.04644927],\n",
       "       [13.91778782, 13.32153794, 15.00979725],\n",
       "       ...,\n",
       "       [13.84389403, 13.11281116, 11.80066787],\n",
       "       [13.90639802, 13.77199267, 12.2819515 ],\n",
       "       [14.01490711, 14.42432237, 12.95433807]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "There is also a universal function \"fetch_block\"\n",
    "It can fetch both old-style filenames and new-style URIs just by block ID\n",
    "\"\"\"\n",
    "\n",
    "polychrom.polymerutils.fetch_block(\"test\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': array([[13.76909954, 13.75941642, 13.88492131],\n",
       "        [14.32039342, 12.95625228, 14.04644927],\n",
       "        [13.91778782, 13.32153794, 15.00979725],\n",
       "        ...,\n",
       "        [13.84389403, 13.11281116, 11.80066787],\n",
       "        [13.90639802, 13.77199267, 12.2819515 ],\n",
       "        [14.01490711, 14.42432237, 12.95433807]]),\n",
       " 'spam': array([1, 2, 3]),\n",
       " 'block': 2,\n",
       " 'eggs': \"I don't eat green eggs and ham!!!\",\n",
       " 'kineticEnergy': 7.695460831782844,\n",
       " 'potentialEnergy': 5.062703028966515,\n",
       " 'time': 1.358945156125511}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "By default it fetches XYZ only, but can do full output\n",
    "(of course in the old-style filenames there is no full output so default is False)\n",
    "\"\"\"\n",
    "\n",
    "polychrom.polymerutils.fetch_block(\"test\",2, full_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU': '0',\n",
       " 'N': 10000,\n",
       " 'PBCbox': False,\n",
       " 'collision_rate': 0.01,\n",
       " 'error_tol': 0.001,\n",
       " 'integrator': 'variableLangevin',\n",
       " 'length_scale': 1.0,\n",
       " 'mass': 100,\n",
       " 'max_Ek': 10,\n",
       " 'platform': 'CPU',\n",
       " 'precision': 'mixed',\n",
       " 'temperature': 300,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finally, loading the saved file with initial conformations. \n",
    "\"\"\"\n",
    "load_hdf5_file(\"test/initArgs_0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple things are saved as attrs\n",
      "('GPU', '0')\n",
      "('N', 10000)\n",
      "('PBCbox', False)\n",
      "('collision_rate', 0.01)\n",
      "('error_tol', 0.001)\n",
      "('integrator', 'variableLangevin')\n",
      "('length_scale', 1.0)\n",
      "('mass', 100)\n",
      "('max_Ek', 10)\n",
      "('platform', 'CPU')\n",
      "('precision', 'mixed')\n",
      "('temperature', 300)\n",
      "('verbose', False)\n",
      "\n",
      " groups of the data files are: \n",
      "[('15', <HDF5 group \"/15\" (2 members)>), ('16', <HDF5 group \"/16\" (2 members)>), ('17', <HDF5 group \"/17\" (2 members)>), ('18', <HDF5 group \"/18\" (2 members)>)]\n",
      "\n",
      " looking at block 15 datasets\n",
      "[('pos', <HDF5 dataset \"pos\": shape (10000, 3), type \"<f8\">), ('spam', <HDF5 dataset \"spam\": shape (3,), type \"<i8\">)]\n",
      "\n",
      " looking at block 15 attrs\n",
      "[('block', 15), ('eggs', \"I don't eat green eggs and ham!!!\"), ('kineticEnergy', 6.885725679584632), ('potentialEnergy', 5.6061969414261705), ('time', 4.237162721676979)]\n",
      "Note that blocks in simulation and in a reporter are syncronized for a simple simulation when you're saving every block starting right away\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "And how it actually looks in HDF5\n",
    "\"\"\"\n",
    "import h5py \n",
    "\n",
    "print(\"simple things are saved as attrs\")\n",
    "\n",
    "for i in h5py.File(\"test/initArgs_0.h5\").attrs.items():\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "myfile = h5py.File(\"test/blocks_15-18.h5\",'r') \n",
    "\n",
    "print(\"\\n groups of the data files are: \")\n",
    "print(list(myfile.items()))\n",
    "\n",
    "\n",
    "print(\"\\n looking at block 15 datasets\")\n",
    "print(list(myfile[\"15\"].items()))\n",
    "\n",
    "\n",
    "print(\"\\n looking at block 15 attrs\")\n",
    "print(list(myfile[\"15\"].attrs.items()))\n",
    "\n",
    "print(\"Note that blocks in simulation and in a reporter are syncronized for a simple simulation \"\n",
    "      \"when you're saving every block starting right away\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
